# WCSN
This repository proposes a novel state-pathology separation network based on wavelet coherence (WCSN) to automatically detect depression using few channel Functional near-infrared spectroscopy (fNIRS) signals.

This project requires Python 3.9 and Tensorflow 2.10 environment.

# Introduction
We proposes a novel state-pathology separation network based on wavelet coherence to automatically detect depression using few channel fNIRS signals. Firstly, the fNIRS signals were preprocessed and transformed into two-dimensional feature maps using a wavelet coherence method. Following this, a wrapped exhaustive search was applied to select the optimal subset of feature maps, which was then utilized to reconstruct the dataset. Finally, samples were classified using the state-pathology separation network that employed a dual-encoder convolutional autoencoder (DCoAE) module to separate the feature maps into state features and pathology features, while a convolutional neural network (CNN) module distinguished Major Depressive Disorder (MDD) patients from healthy controls based on only pathology features.

# Data preprocessing
Four distinct cerebral hemodynamic variables were obtained from the left and right sides of the subject's forehead. The probe pads were positioned at the FP1 and FP2 locations according to the international 10-20 system. Specifically, the concentration changes measured included left prefrontal hemoglobin (L-Hb) and oxygenated hemoglobin (L-HbO2), as well as right prefrontal hemoglobin (R-Hb) and oxygenated hemoglobin (R-HbO2), with a sampling frequency of 10 Hz. To enhance the comparability of fNIRS signals across subjects, the z-score standardization was utilized. The low-frequency range of cerebral hemodynamic variables reflects autonomic nerve and myogenic activity information. Therefore, band-pass filtering was conducted between 0.0095-0.145 Hz.

For each cerebral hemodynamic variable, feature maps were obtained by performing WTC. WTC is a type of wavelet transform that is calculated by continuous wavelet transform and cross wavelet transform. Its output is a two-dimensional map with values that describe the degree of local correlations in the time-frequency domain between the two time series. Using the Morlet wavelet as mother wavelet function, WTC was used to calculate the WTC coefficient maps of L-Hb and L-HbO2, R-Hb and R-HbO2, L-Hb and R-Hb, as well as L-HbO2 and R-HbO2, resulting in four corresponding feature maps.

In line with the experimental protocol of the facial expression recognition task, 40 segments were extracted from the feature maps corresponding to the fear, happy, and sadness blocks, respectively, with the starting point being the initiation of each trial. Additionally, 40 segments were obtained from the data recorded during the resting state after the task. In total, each participant was recorded for a total of 160 segments, with each segment having a duration of 5 seconds. The segments were then labeled as either MDD or health based on the participant’s category. The segments obtained from 49 participants within the same task period were aggregated to generate four datasets, namely fear, happy, sadness, and resting, respectively.

# Models
Samples were classified using the state-pathology separation network that employed a DCoAE module to separate the feature maps into state features and pathology features, while a CNN module distinguished MDD patients from healthy controls based on only pathology features.


Autoencoder is a deep learning model that is designed to learn the hidden distribution of input data by utilizing its encoder and decoder architecture. The encoder converts data into latent vectors while the decoder reconstructs the original data from the latent vectors. In general, the encoder can be employed for data dimensionality reduction and feature extraction. Building on this foundation, this study proposed a novel DCoAE module based on feature disentanglement. The DCoAE employed two encoders to extract the pathological and state features from the feature maps separately. Subsequently, only the pathological features were retained for subsequent classification.

Specifically, the proposed DCoAE was composed of two encoders, Ep and Es, as well as a decoder, denoted as D. Ep was responsible for the extraction of pathological features, while Es extracted state features. The architecture of each encoder comprised two consecutive convolutional layers, each of which was succeeded by a batch normalization (BN) layer and an average pooling layer. The convolutional layers served the purpose of extracting features, with rectified linear unit (ReLU) activation function being employed. The average pooling layers were utilized to reduce the dimensions of the data. Prior to entering the decoder, pathological and state features extracted by Ep and Es, respectively, were fused through addition. The decoder, D, implemented three sequential convolutional layers with leaky ReLU activation function for data reconstruction and two up-sampling layers to restore the original data shape. The first two convolutional layers were followed by a BN layer and an up-sampling layer. Padding zero was used in the up-sampling layer to increase the map size.

Drawing on the concept of feature disentanglement, two supervised constraints, namely cross-reconstruction loss and triplet loss, were employed to realize the extraction and separation of pathological features and state features. To optimize the model, we incorporated these two supervised constraints into the loss function of DCoAE and subsequently minimized it.


With its advantages such as local perception, weight sharing, translation invariance, and automatic feature extraction, CNN has been extensively applied in diverse domains such as image processing, image recognition, behavioral cognition, speech recognition, and clinical medicine. In this study, based on the classical CNN model, a five-layer CNN was adopted to process the pathological features extracted by Ep to achieve the identification of MDD. This CNN consisted of two convolutional layers, four BN layers, two average pooling layers, and three fully connected (FC) layers. The softmax activation function was utilized in the last FC layer, while the ReLU activation function was employed in the remaining FC layers and all convolutional layers. Each convolutional layer was followed by an average pooling layer. BN layers were placed after the two convolutional layers and the first two FC layers. The cross-entropy loss function was utilized to calculate the CNN model’s classification loss.

# Feature map selection
The wrapper exhaustive search was utilized to select the optimal subset of feature maps. The selection process is detailed as follows:
First, all non-empty subsets of the feature map set were used to reconstruct the training set, which is then divided into training set 1 and validation set 1. Subsequently, the reconstructed data was utilized to train and validate the state-pathology separation network, yielding the validation accuracy for each subset as the quality assessment metric. Finally, the subset with the highest quality was designated as the optimal subset.

# Training and testing strategy
The DCoAE module requires the computation of two supervised constraints using a minimum of two datasets concurrently. For training and testing the DCoAE and CNN module, a total of 11 combined datasets were employed, derived from fear, happy, sadness, and resting datasets. It is important to note that the combination of datasets simply refers to a straightforward mixing of samples. To obtain the performance of the state-pathology separation network more reliably, dual cross-validation was employed. The specific process for training and testing the model using each combined dataset is as follows:

Seven-fold cross-validation was employed for model training and testing. Data from 49 subjects were divided into seven groups, each consisting of data from 3 MDD patients and 4 healthy participants, ensuring that each subject's data was included in only one group. For each fold, one group was designated as the test set, while the remaining six groups served as the training set. Initially, six-fold cross-validation was conducted on the training set to determine the optimal subset of feature maps. In each fold, one group of the training set was used as validation set 1, while the remaining five groups constitute training set 1. Both sets were utilized for calculating the qualities of the feature map subsets. This process was repeated six times, and the resulting qualities were averaged to obtain the qualities of the subsets across the entire training set. The subset with the highest quality was selected as the optimal feature subset for the reconstruction of the entire dataset. Next, the training set was randomly divided into two parts: training set 2 (83.3%) and validation set 2 (16.7%), which were used for training and validating the state-pathology separation network. During training, the DCoAE and CNN modules were alternately trained. Specifically, in each training epoch, the loss for the DCoAE was computed using the training set 2, followed by backpropagation based on this loss. The pathological features were extracted using Ep, and the classification loss was obtained by inputting those features into the CNN. Backpropagation based on the classification loss was performed for both Ep and the CNN module. During the backpropagation process, the model weights were updated using a Stochastic Gradient Descent (SGD) optimizer. The validation set 2 was input into the state-pathology separation network to obtain the validation loss. An early stopping method and a dynamic learning rate reduction (with an initial learning rate of 0.01) were implemented to further optimize the model. The batch size was set to 70, with a maximum of 200 training epochs. Finally, upon completion of training, the test set was input into the network to derive the confusion matrix for that fold. This process was repeated seven times, ensuring that each group was selected as the test set once. The evaluation metrics for the WCSN algorithm were calculated based on the confusion matrix for the entire dataset, which was derived from the summation of the seven individual confusion matrices.

# Assessment criteria
The relevant performance parameters were defined by true positive (TP), false positive (FP), true negative (TN), and false negative (FN), which respectively denote the number of correctly classified MDD segments, the number of incorrectly classified healthy segments, the number of correctly classified healthy segments, and the number of incorrectly classified MDD segments. Then, we considered five evaluation metrics, namely accuracy, precision, recall, F1 score, and accsubject, to quantitatively assess the effectiveness of the proposed WCSN algorithm. Correctly classified subjects were defined as those with more than half of their segments classified correctly. Here, accsubject is defined as the ratio between the number of correctly classified subjects and the number of all subjects.
